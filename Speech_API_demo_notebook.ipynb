{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Speech API demo notebook\n",
    "This notebook demonstrates simply  \n",
    "* how you can send a speech to Speech api to get converted to text  \n",
    "* how you can translate a text by using translator api\n",
    "* how you can send a text to get the spoken version of it\n",
    "* how to play the aıdio via python \n",
    "\n",
    "Below you will find the required packages to be installed in your python enviroment.  \n",
    "You can either install from here or your terminal vindow via [activating your enviroment](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#activating-an-environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-cognitiveservices-speech\n",
    "!pip install websocket-client\n",
    "!pip install playsound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the [Azure Cognitive Services Speech SDK](https://docs.microsoft.com/en-us/azure/cognitive-services/Speech/home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your speech api and translator api keys. *(for production you may prefer them to be saved in an enviroment variable)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_key, service_region = \"YourSubscriptionKey\", \"YourServiceRegion\" ## \"westeurope\",\"westus\" etc.\n",
    "\n",
    "translator_subscriptionKey = \"YourSubscriptionKey\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text To Speech Part:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The language is specified in BCP-47 format. Language codes can be found [here](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SST settings\n",
    "speech_language=\"tr-TR\" #Turkish\n",
    "#speech_language=\"en-US\"\n",
    "#speech_language=\"ar-EG\" #Egyptian Arabic\n",
    "#speech_language=\"ar-SA\" #Saudi Arabic #not supported yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Voice codes codes can be found [here](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support#standard-voices). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS settings\n",
    "voice_language=\"Microsoft Server Speech Text to Speech Voice (tr-TR, SedaRUS)\" #Turkish\n",
    "#voice_language=\"Microsoft Server Speech Text to Speech Voice (en-US, Guy24KRUS)\" #English\n",
    "#voice_language=\"Microsoft Server Speech Text to Speech Voice (ar-EG, Hoda)\"#Egyptian Arabic\n",
    "#voice_language=\"Microsoft Server Speech Text to Speech Voice (ar-SA, Naayf)\"#Saudi Arabic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following code snippet shows how speech can be recognized from audio input from the default microphone (make sure the audio settings are correct), and how to interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_config = speechsdk.SpeechConfig(subscription=speech_key, \n",
    "                                       region=service_region,\n",
    "                                       speech_recognition_language=speech_language)\n",
    "\n",
    "speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**While running below line also play/speak the sentences you want to get logged as text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = speech_recognizer.recognize_once()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the api:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized: Bu akşam bir yerlere mi gitsek diyorum\n"
     ]
    }
   ],
   "source": [
    "if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "    print(\"Recognized: {}\".format(result.text))\n",
    "    input_text =format(result.text)\n",
    "elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "    print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
    "elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = result.cancellation_details\n",
    "    print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        print(\"Error details: {}\".format(cancellation_details.error_details))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate The Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, uuid, json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalize the required Translator API parameter definitions, **subscription key** (done already at the key defnition part), **api url**, **from-to which language** *(if you do not identify from it decides by itself by usng language detection capabilities)*, and **header information**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator_base_url = 'https://api.cognitive.microsofttranslator.com/translate?api-version=3.0'\n",
    "translator_params = '&to=en' #translate to english \n",
    "translator_constructed_url = translator_base_url + translator_params\n",
    "translator_headers = {\n",
    "    'Ocp-Apim-Subscription-Key': translator_subscriptionKey,\n",
    "    'Content-type': 'application/json',\n",
    "    'X-ClientTraceId': str(uuid.uuid4())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the translator rest api query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'detectedLanguage': {'language': 'tr', 'score': 1.0}, 'translations': [{'text': \"I'm saying we should go somewhere tonight.\", 'to': 'en'}]}]\n"
     ]
    }
   ],
   "source": [
    "body = [{ 'text' : input_text }]\n",
    "\n",
    "translator_request = requests.post(translator_constructed_url, headers=translator_headers, json=body)\n",
    "\n",
    "translated_input = translator_request.json()\n",
    "print(translated_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text To Speech Part:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**If you want to use the input you gave via microphone do not run below 2 line:** </span>\n",
    "\n",
    "<span style=\"color:blue\">**If you want to give another input to the TTS run below 2 line:** </span>\n",
    "\n",
    "<span style=\"color:red\">**------------------------------------------------------------------------------------------------------**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: input = raw_input\n",
    "except NameError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text= input(\"What would you like to convert to speech: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**------------------------------------------------------------------------------------------------------**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the neccesary packages to build the requred XML format for the REST query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, time\n",
    "from xml.etree import ElementTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use [TTS REST API](https://docs.microsoft.com/en-us/azure/cognitive-services/Speech/API-Reference-REST/BingVoiceOutput) with python.  \n",
    "The subscription_key is your unique key from the Azure portal.  \n",
    "The text-to-speech REST API requires an access token for authentication.  \n",
    "Therefore, first we define required information for  the token exchange,  \n",
    "get the token for the session  and call the text-to-speech API.  \n",
    "To get an access token, an exchange is required. This sample exchanges your Speech Service subscription key for an access token using the issueToken endpoint.  \n",
    "Then we build the required headers for TTS, and set the REST CALL XML structure.\n",
    "\n",
    "After calling the API we will write the audio in the response to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_token_url = \"https://\"+service_region+\".api.cognitive.microsoft.com/sts/v1.0/issueToken\"\n",
    "token_headers = {'Ocp-Apim-Subscription-Key': speech_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Status code: 200\n",
      "Your TTS is ready for playback.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "access_token = str(requests.post(fetch_token_url, headers=token_headers).text)\n",
    "\n",
    "constructed_url = \"https://\"+service_region+\".tts.speech.microsoft.com/cognitiveservices/v1\"\n",
    "\n",
    "headers = {\n",
    "            'Authorization': 'Bearer ' + access_token,\n",
    "            'Content-Type': 'application/ssml+xml',\n",
    "            'X-Microsoft-OutputFormat': 'riff-24khz-16bit-mono-pcm',\n",
    "            'User-Agent': 'TurkcellSSTTSSDemo'#Application name:The application name is required and must be fewer than 255 characters.\n",
    "        }\n",
    "xml_body = ElementTree.Element('speak', version='1.0')\n",
    "xml_body.set('{http://www.w3.org/XML/1998/namespace}lang', speech_language)\n",
    "voice = ElementTree.SubElement(xml_body, 'voice')\n",
    "voice.set('{http://www.w3.org/XML/1998/namespace}lang', speech_language)\n",
    "voice.set('name', voice_language)\n",
    "\n",
    "\n",
    "voice.text = input_text\n",
    "\n",
    "body = ElementTree.tostring(xml_body)\n",
    "response = requests.post(constructed_url, headers=headers, data=body)\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    audio_file='sample-' + timestr + '.wav'\n",
    "    with open(audio_file, 'wb') as audio:\n",
    "            audio.write(response.content)\n",
    "            print(\"\\nStatus code: \" + str(response.status_code) + \"\\nYour TTS is ready for playback.\\n\")\n",
    "else:\n",
    "            print(\"\\nStatus code: \" + str(response.status_code) + \"\\nSomething went wrong. Check your subscription key and headers.\\n\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can play the audio file returned anad saved from the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "playsound(audio_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
